he hecho un poco de limpieza de variables, aparte de las que no se podian usar he quitado algunas que creo que no daban mucha info.

tambien he pasado algunas a integer ya que spark no las reconocia y he vaciado todas las rows que tuviesen nulls o na,
aunq quiza en las varialbes que son string no haya salido bien, ya que puede reconocerme un NA como una codigo de aeropuerto ...

he combinado la columna Distance con CRSElapsedTime(duracion planeada de vuelo), y he añadido esto como nueva variable algo
asi como Velocidad planeada de vuelo ( CRSPlanned Speed ).
lo que ahora no se es si deberiamos quitar Distance, CRSElapsedTime, ambas o dejarlas todas. Puede que tambien dependa del modelo.

tambien he pasado varias variables que me parecian categoricas a onehotencoding, que se necesita para la mayoria de algoritmos.

tambien habia pensado que quiza deberiamos categorizar la target ( ArrDelay ) en por ej retraso bajo, medio , alto y muy alto.
para aplicar trees y tal puede ayudar.
aunque tambien se puede usar asi para un modelo y de otra manera para otro.

y por ultimo pues me dio por ver si la hora del dia influia en el retraso, he aplicado kmeans a DepTime y a CRSArrTime.
Y no se si es muy concluyente pero el Silhouette coef da que la mejor division es con 2 clusters y si mirais los centroides
parece que cuanto mas pronto es el vuelo menos es el retraso y cuanto mas tarde es el vuelo mas largo es el retraso,
esto para mi tiene sentido ya que  por la mañana las compañias suelen empezar de 0 y luego van acumulando retrasos hasta la noche.
entonces si lo veis bien podemos categorizar esas 2 variables en 2 clases ( mañana y tarde por ej) o quedarnos solo con una

he estado mirando un poco como hacer ver la mutual information y no he encontrado mucho.
habia pensado en hacer PCA y ver que variables influyen mas, pero ahora no se bien si habria que incluir la target variable o no ( creo q si )

DISCULPAD LA CHAPADA jajaja
-------------------------------------------------------------
Hemos hecho también un análisis de las variables. La hemos resumido en el archivo excel que hemos subido.

Hemos sacado una gráfica comparando el delay por vuelo de cada aerolínea(UniqueCarrier). Hemos sumado todos los valores positivos de delay y 
dividido entre el número de vuelos totales con delay, todo ello 'filtrando' por aerolinea. Hemos visto que hay diferencias entre las aerolíneas, 
por lo que pensamos que está bien mantener esas columnas.

En lugar de quitar las columnas de 'Cancelled' y 'CancellationCode', eliminaríamos sólo las filas con vuelos cancelados, y luego ya eliminaríamos ambas columnas.

Lo de onehotencoding lo vemos bien sí.

En cuando a lo de calcular la velocidad, realmente no lo vemos 100% necesario porque no sabemos si tendría que ver con el delay.

Sobre la target column, podemos probar a aplicar algoritmos sin necesidad de categorizar esa columna (como el Artificial neural network o 
el regression... no recordamos exactamente cual era al que nos referimos jajaja).

Nosotros la columna de Flightnum no la quitaríamos, sino que quitaríamos las de Origin y Dest, porque el flightnum ya está asociado a un recorrido (tipo, Madrid-Lisboa
tendría un flight number fijo en todas las instancias con origin madrid y dest lisboa). Y vemos quizás mejor dejar el flightnum en ligar de dos columnas.

Lo de categorizar en dos clases (mañana y tarde) por un lado es raro y por otro  tiene sentido, podríamos probar de las dos formas??

No hemos modificado el código, porque ya cuando decidamos 100% lo de las columnas, etc, pues con lo que estés de acuerdo lo cambiamos pero por no entrar en bucle de cambios!
Dinos qué opinas!!

----------------------------------------------------------------

En cuanto al tratamiento de las variables, hemos:
	-Dejado de ejecutar el calculo de la velocidad porque comparando resultados es mejor dejar las otras dos columnas 'distance' y 'CRSElapsedTime'.
	-Convertido a enteros 'distance' y 'CRSElapsedTime'.
	-Cambiado un poco la funcion de quitar NA, para no eliminar posibles orígenes y destinos con NA en el nombre ('SNA' y 'BNA').
	-Eliminado las columnas de 'DayofMonth', 'Month'. Intentamos de varias maneras cambiar el formato a fecha, sin buenos resultados, y no tiene mucho sentido dejar una 
  columna que asemeje, por ejemplo, un sábado dia 1 que correspondiese a enero, a un día 1 miércoles que correspondiese a marzo.
 	-Convertido 'DayOfWeek' en un one hot encoding, 'DayOfWeekOHE'.
	-En cuanto a las variables 'DepTime' y 'CRSArrTime' hiciste dos transformaciones, una en OHE y otra cambiando el integer. Tras probar con los algoritmos hemos elegido
  que las mejores eran las que están en formato integer, y hemos eliminado las otras columnas.

Después preparamos los datos para meterlos en los algoritmos de ML con el vector assembler.

Luego hemos probado a hacer Principal Components y escalar los datos (MinMaxScaler), pero no ha dado buenos resultados porque a la hora de aplicar los algoritmos no 
salen bien, dan un RMSE susperior al que sale sin hacer ningun cambio.


Después aplicamos los algoritnmos, hemos implementado tres tipos:
	-Linear Regression. (En este también utilizamos Cross Validation, para configurar los parametros del metodo).
	-GeneralizedLinear Regression (con family=Gaussian y link=identity).(En este también utilizamos Cross Validation, para configurar los parametros del metodo).
	-Decision Tree Regression.

Para continuar, creo que uno de los problemas que tenemos es que en nuestro modelo final, al hacer el Vector assembler nos quedan como 500 variables, esto hace que 
los metodos funcionen muy lentos y los resultados no sean buenos. El hecho de que haya tantas variables se debe al OHE de origin y destino que hace añadir 
236 variables cada una. 
Quizás habría que pensar en otra forma de tratar esas features, o utilizar un filtro de variables y quedarnos solo con algunas. 

Al final he probado con un selector de atributos que viene en la documnetacion se llama ChiSqselector, escogiendo los 25 atributos mas importantes, y el resultado 
de los algoritmos no es malo.
